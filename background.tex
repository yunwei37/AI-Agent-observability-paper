\section{The Agent Observability Crisis}

\subsection{AI Agent Architecture}
AI agents represent a new class of software systems that combine language models with environmental interactions. These systems typically consist of three core components: (1) an LLM backend that provides reasoning capabilities, (2) a tool execution framework that enables system interactions, and (3) a control loop that orchestrates prompts, tool calls, and state management. Popular frameworks such as LangChain~\cite{langchain}, AutoGen~\cite{autogen}, and Claude Code implement variations of this architecture. The key characteristic distinguishing AI agents from traditional software is their ability to dynamically construct execution plans based on natural language objectives—an agent tasked with "analyze this dataset" might autonomously decide to install packages, write analysis scripts, execute them, and interpret results—all without predetermined logic paths. This flexibility comes from the LLM's ability to generate arbitrary code and command sequences.

\subsection{The Challenge: A Fundamental Semantic Gap}
The autonomy of AI agents creates a fundamental challenge that invalidates traditional monitoring paradigms: the **semantic gap**. This gap is the chasm between an agent's high-level, semantic *intent* (the "why," captured in LLM interactions) and its low-level system *actions* (the "what," observed as system calls). This chasm is created by two core agent behaviors: **Dynamic Execution Paths**, where an agent's operational sequence emerges from non-deterministic reasoning, and **Cross-Boundary Interactions**, where agents spawn subprocesses (\texttt{bash}, \texttt{curl}, \texttt{git}) that escape the monitoring scope of the parent process. Because of this gap, observing only the intent or only the action is insufficient and misleading, demanding a new approach that can holistically link the two.

\subsection{Failure Scenarios: The Gap in Action}
The danger of the unbridged semantic gap is not theoretical. It manifests in significant reliability and security risks, as demonstrated by these real-world failure scenarios. In an \textbf{Unintended System Modification} incident, an AI agent tasked with code review misinterprets its instructions and begins modifying the production codebase—the semantic gap is exposed when application-level tools see the benign \emph{intent} ("review code") but are completely blind to the destructive system \emph{actions} (\texttt{git commit} and file modifications) occurring in a subprocess. A \textbf{Costly Reasoning Loop} occurs when a data analysis agent enters an infinite cycle calling expensive LLM APIs to solve an impossible problem, consuming thousands of dollars—framework logs reveal the \emph{action} (high volume of API calls) but provide no insight into the semantic \emph{intent}, which is a looping pattern of thought, making it impossible to distinguish between productive work and a costly failure mode without bridging the gap. In a \textbf{Cross-Process Exploitation}, an agent compromised via prompt injection writes a malicious shell script to \texttt{/tmp} and executes it—the semantic gap here is critical as system monitors see the file-write and process-execution \emph{actions}, but without linking them to the malicious \emph{intent} from the prompt, they appear as benign, uncorrelated events, and only by bridging the gap can the full attack narrative be reconstructed. These incidents exemplify a new threat model unique to AI agents, where the disconnect between intent and action can lead to prompt injection attacks, goal drift, and unintended capability escalation.

\subsection{Inadequacy of Existing Approaches}
Confronted with these failures, current observability solutions prove inadequate because each operates on only one side of the semantic gap.

\textbf{SDK-Based and Proxy-Based Instrumentation} solutions like LangSmith~\cite{langsmith}, Langfuse~\cite{langfuse}, and Helicone~\cite{helicone} operate on the **intent side** of the gap. They excel at capturing LLM prompts, responses, and tool choices. However, they are blind to any system **actions** that occur outside the instrumented framework, such as operations within a spawned shell script. Furthermore, their reliance on in-process hooks makes them brittle against rapid framework evolution and assumes a cooperative agent that will not be compromised to bypass logging.

\textbf{Generic System-Level Monitoring} tools like Falco~\cite{falco} and Tracee~\cite{tracee} operate on the **action side**. They provide comprehensive visibility into every system call and process execution but lack all semantic context. To these tools, an agent writing a file is just a file write; they cannot determine the **intent** behind it. As demonstrated in the exploitation scenario, they can report that a script was executed from \texttt{/tmp}, but cannot link this action back to the agent's reasoning, failing to distinguish a malicious attack from a legitimate task.

No existing solution can simultaneously capture semantic intent and system actions, maintain visibility across process boundaries, and remain resilient to framework changes. This critical failure to bridge the semantic gap motivates our novel approach.

\subsection{eBPF: A Foundation for Boundary Tracing}
To bridge the semantic gap, we require a technology that can observe both network communication and kernel activity safely and efficiently. eBPF (extended Berkeley Packet Filter) is a fundamental advancement in kernel programmability that provides this capability~\cite{brendangregg}. Originally for packet filtering, eBPF is now a general-purpose, in-kernel virtual machine powering modern observability and security tools~\cite{ebpfio,cilium}. For AI agent observability, eBPF is uniquely suited: it allows observation at the exact boundaries where agents interact with the system, enabling both TLS interception for semantic *intent* and syscall monitoring for system *actions* with minimal performance overhead. Crucially, its kernel-enforced safety guarantees—verified termination, memory safety, and resource limits—make it ideal for production environments, providing a stable and tamper-proof foundation upon which to build our solution~\cite{kerneldoc}.