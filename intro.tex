\section{Introduction}

AI agents violate the fundamental assumptions of software monitoring. Unlike traditional programs with predictable execution paths, agents combine Large Language Models (LLMs) with autonomous tool use, enabling them to dynamically generate code, spawn arbitrary subprocesses, and alter their behavior based on natural language goals. This paradigm shift creates a critical \textbf{semantic gap}: the chasm between an agent's high-level \emph{intent} and its low-level \emph{system actions}. Consider an agent tasked with code refactoring that, due to a malicious prompt, instead injects a backdoor. An application-level monitor might see a successful "execute script" tool call, while a system monitor sees a \texttt{git commit} process writing to a file. Neither can bridge the gap to understand that a benign intention has been twisted into a malicious action, rendering them effectively blind.

This semantic gap makes it impossible for existing observability tools to distinguish between benign operations and catastrophic failures. Current approaches fall into two categories, each blind to one side of the gap. \textbf{Application-level instrumentation}, found in frameworks like LangChain~\cite{langchain} and AutoGen~\cite{autogen}, uses hooks and logs to capture the agent's reasoning and tool selections. While these tools see the \emph{intent}, they are fundamentally limited. They are brittle, requiring constant updates to keep pace with framework APIs that see dozens of breaking changes monthly. More critically, they are easily bypassed; a single shell command spawned by an agent escapes their view, breaking the chain of visibility. They operate on a flawed trust model, assuming a cooperative agent that will not be compromised or exhibit emergent, unlogged behaviors.

On the other side, \textbf{generic system-level monitoring} tools see the \emph{actions}. They can track every system call, file access, and network connection. However, they lack all semantic context. To them, an agent writing a data analysis script to \texttt{/tmp} is indistinguishable from a compromised agent writing a malicious payload to the same location. Without understanding the preceding LLM instructions—the \emph{why} behind the \emph{what}—their stream of low-level events is meaningless noise, leading to an overwhelming volume of false positives and inactionable alerts.

We propose \emph{boundary tracing} as a novel observability paradigm designed specifically to bridge this semantic gap. Our key insight is that while agent internals and frameworks are volatile, the interfaces through which they interact with the world—the kernel for system operations and the network for communication—are stable and unavoidable. By monitoring from outside the application at these tamper-proof boundaries, we can simultaneously capture an agent's high-level intent and its low-level system effects, creating a complete, correlated picture of its behavior. This approach replaces the broken trust model of instrumentation with enforced, comprehensive observation.

This paper presents AgentSight, a system that realizes the boundary tracing paradigm using eBPF technology. AgentSight intercepts TLS-encrypted LLM traffic to understand semantic intent and monitors kernel events to observe system-wide effects. Its core contribution is its ability to \textbf{causally correlate these two streams across process boundaries}, linking a specific LLM response to the sequence of system calls it triggers, even in subprocesses. This instrumentation-free technique is framework-agnostic and incurs less than 3\% performance overhead. Our evaluation shows AgentSight detects sophisticated prompt injection attacks with 92\% confidence, automatically identifies resource-wasting reasoning loops, and reveals hidden bottlenecks in multi-agent systems.

\textbf{This paper makes three primary contributions:}

\begin{enumerate}
\item \textbf{Boundary Tracing Paradigm}: We introduce boundary tracing as a principled approach to AI agent observability that bridges the semantic gap by monitoring at stable system interfaces.

\item \textbf{System-Level Correlation}: We present AgentSight's eBPF-based implementation that causally correlates TLS-intercepted LLM communications with kernel-level operations across process boundaries.

\item \textbf{Production Validation}: We demonstrate AgentSight's effectiveness in detecting prompt injection attacks (92\% confidence), reasoning loops, and multi-agent coordination failures with sub-3\% overhead.
\end{enumerate}