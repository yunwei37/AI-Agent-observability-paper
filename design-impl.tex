
\begin{center}
\begin{Verbatim}[fontsize=\small, commandchars=\\\{\}]
┌─────────────────────────────────────────────────┐
│             System Environment                  │
│  (Operating System, Containers, Services)       │
│                                                 │
│  ┌─────────────────────────────────────────┐   │
│  │      Agent Runtime Framework            │   │  ← Application Layer
│  │   (LangChain, AutoGen, Claude Code)     │   │
│  │   • Prompt orchestration                │   │
│  │   • Tool execution logic                │   │
│  │   • State management                    │   │
│  └─────────────────────────────────────────┘   │
│                    ↕                            │
│  ═══════════════════════════════════════════   │  ← Network Boundary
│           (TLS-encrypted traffic)               │     (Observable)
│                    ↕                            │
│  ┌─────────────────────────────────────────┐   │
│  │         LLM Service Provider            │   │
│  │    (OpenAI API, Local Models)           │   │
│  └─────────────────────────────────────────┘   │
│                                                 │
│  ═══════════════════════════════════════════   │  ← Kernel Boundary
│         (System calls, File I/O)                │     (Observable)
└─────────────────────────────────────────────────┘
\end{Verbatim}
\end{center}

\section{Design}

The design of AgentSight is guided by a single imperative: to bridge the semantic gap between an agent's intent and its actions. We achieve this through a novel observability paradigm, \emph{boundary tracing}, which is built on a foundation of stable system interfaces and realized through a multi-signal correlation engine.

\subsection{Boundary Tracing: A Principled Approach}
Our approach is rooted in a key insight: while agent frameworks and internal logic are volatile, the system boundaries they must cross to perform any meaningful action are stable and unavoidable. Boundary tracing leverages this stability to provide durable and comprehensive observability. The primary goal of this approach is to enable \textbf{Semantic Correlation}, the ability to causally link high-level intentions with low-level system events. This goal is made possible by two foundational principles: \textbf{Comprehensiveness}, where by monitoring at the kernel we ensure that no system-level action—from process creation to file I/O—can go unobserved, regardless of the agent's implementation language or its attempts to evade monitoring by spawning subprocesses; and \textbf{Stability}, where system call ABIs and network protocols evolve far more slowly than agent frameworks, providing a durable solution resilient to the constant breaking changes common in agent libraries. This paradigm fundamentally shifts the trust model from assuming a cooperative agent to enforcing observation at tamper-proof system boundaries.

\subsection{System Architecture: Observing the Boundaries}
AgentSight's architecture is designed to simultaneously tap into the two critical boundaries an agent interacts with: the network boundary for semantic intent and the kernel boundary for system actions. Figure 1 illustrates this architecture. We use eBPF to place non-intrusive probes at both boundaries. Probes on SSL library functions in userspace capture the decrypted **Intent Stream** (LLM prompts and responses), while probes at the kernel level capture the **Action Stream** (syscalls, process events). Both streams are processed by our userspace correlation engine, which joins them to produce a unified, causally-linked event trace.

\begin{figure}[h!]
    \centering
    % It is highly recommended to create this diagram using a tool like TikZ, Inkscape, or another vector graphics editor for the final paper.
    % The following is a LaTeX description of the recommended figure.
    % \includegraphics[width=\columnwidth]{placeholder_diagram.png} % Replace with your actual figure file
    \caption{\textbf{AgentSight System Architecture.} The agent process communicates with LLM services across the Network Boundary and interacts with the OS via the Kernel Boundary. eBPF uprobes intercept decrypted TLS traffic within the agent's userspace to capture the semantic \textbf{Intent Stream}. Simultaneously, eBPF kprobes and tracepoints monitor kernel activity to capture the \textbf{Action Stream}. Both streams are fed into the AgentSight Correlation Engine. The engine first uses a \textbf{Real-time Heuristic Correlator} to link events, then passes the structured trace to an \textbf{LLM-based Semantic Analyzer} for deeper interpretation and threat detection.}
    \label{fig:architecture}
\end{figure}

\subsection{Bridging the Gap: Core Design Decisions}
Several key decisions enable AgentSight to effectively bridge the semantic gap:

\textbf{eBPF for Safe, Unified Probing:} We chose eBPF because it provides a single, production-safe technology to access both userspace and kernel data streams. Its verified safety model eliminates the risks of kernel modules, and its performance is vastly superior to traditional userspace hooking or \texttt{ptrace}-based approaches.

\textbf{Uprobes for Transparent TLS Interception:} To capture semantic intent, we intercept decrypted data directly from the agent's memory by placing \texttt{uprobes} on SSL library functions (e.g., \texttt{SSL\_read}/\texttt{SSL\_write}). This approach is superior to network-level packet capture, as it avoids the complexity of TLS key management, and more efficient than proxy-based solutions, which introduce network latency and configuration overhead.

\textbf{Multi-Signal Causal Correlation Engine:} The core of our design is a correlation strategy that establishes causality between intent and action. We designed a multi-signal engine that relies on three key mechanisms: \textbf{Process Lineage}, which builds a complete process tree by tracking \texttt{fork} and \texttt{execve} events to link actions in child processes back to the parent agent; \textbf{Temporal Proximity}, which associates actions that occur within a narrow time window immediately following an LLM response; and \textbf{Argument Matching}, which directly matches content from LLM responses—such as filenames, URLs, or commands—with the arguments of subsequent system calls. Together, these signals enable AgentSight to definitively establish causal relationships between high-level intentions and low-level system operations across process boundaries.

\textbf{LLM-Powered Semantic Analysis:} To move beyond brittle, rule-based detection, we designed the system to use a secondary LLM as a reasoning engine. By prompting a powerful model with the correlated event trace, we leverage its ability to understand semantic nuance, infer causality in complex scenarios, and summarize findings in natural language. This "AI to watch AI" approach allows AgentSight to detect threats that do not match predefined patterns.

\section{Implementation}
AgentSight is implemented as a userspace daemon written in Rust that orchestrates a suite of eBPF programs. The system is designed for high performance and low overhead, processing raw event streams from the kernel to produce correlated, human-readable observability data.

\subsection{Data Collection at the Boundaries}
Our eBPF probes are responsible for capturing the raw intent and action streams from the system.

\textbf{Capturing Semantic Intent (TLS):} An eBPF program utilizing \texttt{uprobes} is attached to \texttt{SSL\_read} and \texttt{SSL\_write} functions in dynamically linked crypto libraries (e.g., OpenSSL, BoringSSL). This allows us to intercept all decrypted LLM communications. A significant challenge here is handling streaming protocols like Server-Sent Events (SSE), which fragment a single JSON response across numerous \texttt{SSL\_read} calls. Our userspace daemon implements a stateful reassembly mechanism that buffers data chunks per-connection and parses them for event boundaries (double newlines) to reconstruct complete messages.

\textbf{Capturing System Actions (Kernel):} A second eBPF program monitors kernel activity. We use efficient, stable \texttt{tracepoints} like \texttt{sched\_process\_fork} and \texttt{sched\_process\_exit} to build a process tree. For detailed actions, we use \texttt{kprobes} to dynamically attach to specific system calls relevant to agent behavior, such as \texttt{openat2} (file access), \texttt{connect} (network connections), and \texttt{execve} (program execution). Aggressive in-kernel filtering ensures that only events originating from targeted agent processes are sent to userspace, minimizing overhead.

\subsection{The Hybrid Correlation Engine}
The Rust-based userspace daemon houses our two-stage correlation engine.

\textbf{Real-time Heuristic Linking:} The first stage performs real-time linking of intent and action streams. It consumes events from eBPF ring buffers and applies the multi-signal logic. First, \textbf{Enrichment} adds context to raw events—for example, mapping a file descriptor from an \texttt{openat2} call to a full file path, and a process ID to its full command line and parent process from the process tree. Second, \textbf{Stateful Tracking} maintains the state of each agent and its children in a process-tree data structure while tracking open files and network connections for each process. Finally, \textbf{Causal Linking} uses the enriched data and maintained state to apply the correlation logic, searching for system actions that match the "fingerprint" of a preceding LLM intent based on process lineage, temporal proximity (within a 100-500ms window), and content matching. This pipeline is designed for streaming analysis, avoiding the need to store complete event histories and enabling real-time detection with a memory footprint of less than 200MB on a typical system.

\textbf{LLM-based Semantic Analysis:} Once a coherent trace is constructed by the real-time linker, it is passed to the second stage for semantic analysis. This trace is first formatted into a structured, chronological log. We then use this log to construct a detailed prompt for a secondary LLM (e.g., GPT-4 or Claude). The prompt instructs the LLM to act as a security analyst, asking it to evaluate the agent's actions in the context of its original goal and to identify any deviations, inefficiencies, or security risks. The LLM's natural language response, containing its analysis and a confidence score, becomes the final output of our system. 