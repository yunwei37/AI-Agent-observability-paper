\section{Evaluation}

Our evaluation is guided by two research questions: First, what is the performance overhead of AgentSight in realistic workflows? Second, how effectively does it bridge the semantic gap to detect critical security threats and performance pathologies, while also revealing complex dynamics in multi-agent systems?

\subsection{Performance Evaluation}

\begin{table}[h]
\centering
\caption{Overhead Introduced by AgentSight}
\label{tab:build-overhead}
\begin{tabular}{lrrr}
\toprule
Task & Baseline (s) & AgentSight (s) & Overhead \\
\midrule
Understand Repo & 127.98 & 132.33 & 3.4\% \\
Code Writing & 22.54 & 23.64 & 4.9\% \\
Repo Compilation & 92.40 & 92.72 & 0.4\% \\
\bottomrule
\end{tabular}
\end{table}

 We evaluated AgentSight on a server (Ubuntu 22.04, Linux 6.14.0) using Claude Code 1.0.62 as the test agent. The benchmarks focused on three real-world developer workflows using a tutorial repo\cite{ebpftutorial}: repository understanding with the \texttt{/init} command, code generation for bpftrace scripts, and full repository compilation with parallel builds. Each experiment was run 3 times with and without AgentSight to measure runtime overhead.
Table~\ref{tab:build-overhead} quantifies the runtime overhead of AgentSight across three developer workflows, with a average 2.9\% overhead.  

\subsection{Case Studies}

We evaluated AgentSight's effectiveness through case studies that demonstrate its ability to detect security threats, identify performance issues, and provide insights into complex multi-agent systems.

\subsubsection{Case Study 1: Detecting Prompt Injection Attacks}

We tested AgentSight's ability to detect indirect prompt injection attacks\cite{indirect-prompt-inject}. In our test, a data analysis agent received a crafted prompt that embedded malicious commands within a legitimate request, ultimately causing it to exfiltrate `/etc/passwd`. AgentSight captured the complete attack chain: from the initial LLM interaction with the suspicious webpage to the final sensitive file read, including the intermediate subprocess spawn and outbound connection. The correlated event trace was passed to our observer LLM for analysis, which returned a high-confidence attack score (5/5). The LLM's analysis concluded that the agent's actions, executing a shell command to read `/etc/passwd` and connecting to a non-corporate domain, were logically inconsistent with its stated "analyze sales data" goal, identifying a classic data exfiltration pattern from a successful prompt injection. This demonstrates how combining intent and action provides actionable, context-aware detection.

\subsubsection{Case Study 2: Reasoning Loop Detection}

An agent attempting a complex task entered an infinite loop due to a common tool usage error. It repeatedly called a command-line tool with incorrect arguments, received an error, but then failed to correct its mistake, retrying the exact same failing command. AgentSight's real-time monitors detect this anomalous resource consumption from a trace of 12 API calls and passed it to the observer LLM. The LLM identified the root cause as a persistent tool error, noting the agent was caught in a "try-fail-re-reason" loop; it executed the same failing command, passed the identical error back to the reasoning LLM, and failed to learn from the tool's output. The system triggered an alert after three complete cycles, a configurable threshold, where the agent had already consumed 4,800 tokens. This intervention prevented further resource waste and service degradation, saving an estimated \$2.40 in API cost, and highlighted the importance of semantic-aware monitoring.

\subsubsection{Case Study 3: Multi-Agent Coordination Monitoring}

AgentSight monitored a team of three collaborating software development agents, capturing 12,847 total events. For instance, Agent B was blocked for 34\% of its total wall-clock time waiting on Agent A's multiple design revisions, which triggered cascading rework. File locking contention between Agent B's implementation and Agent C's testing caused 23 retry cycles. The analysis demonstrated that while the agents developed some emergent coordination, explicit mechanisms could reduce total runtime by up to 25\% on this workload and message-based communication could eliminate most of the polling overhead. This reveals how boundary tracing uniquely captures multi-agent system dynamics that application-level monitoring cannot observe across process boundaries.

% \subsubsection{Case Study 1: Detecting Prompt Injection Attacks}

% We tested AgentSight's ability to detect indirect prompt injection attacks\cite{indirect-prompt-inject} where a data analysis agent received a crafted prompt embedding malicious commands within a legitimate request to analyze sales data, ultimately exfiltrating /etc/passwd. AgentSight captured the complete attack chain: LLM interaction with suspicious prompt (T+0ms), agent-generated Python script with embedded curl command (T+125ms), subprocess spawn (T+342ms), outbound HTTPS connection to suspicious domain (T+367ms), and sensitive file read (T+368ms). The correlated event trace was passed to our observer LLM for analysis. The LLM returned a confidence score 5(1-5) from  for an attack and generated the following explanation: \emph{"Analysis: The agent's initial intent was to 'analyze sales data'. However, it immediately executed a shell command to read /etc/passwd and then initiated a network connection to a non-corporate domain. This sequence of actions is not logically consistent with the stated goal and is a classic pattern of a successful prompt injection attack leading to data exfiltration."} This demonstrates how LLM-based analysis provides not just detection, but actionable, context-aware explanations.

% \subsubsection{Case Study 2: Reasoning Loop Detection}

% An agent attempting a complex task entered an infinite reasoning loop with circular dependencies where solving X required solving Y, but solving Y required solving X, a pattern common when agents encounter problems outside their training distribution. AgentSight's real-time monitors flagged anomalous resource consumption. The corresponding trace of 12 API calls was sent to the observer LLM, which identified the root cause: \emph{"Analysis: The agent is in a reasoning loop. It is asking semantically identical questions in alternating order ('How to do X to get Y?' followed by 'How to get Y to do X?'). The problem scope is not being reduced between calls, indicating zero progress. Recommend terminating the agent to prevent further resource waste."} The system triggered an alert after detecting three complete cycles where the agent had consumed 4,800 tokens, with AgentSight's intervention saving an estimated \$2.40 in API costs and preventing service degradation, demonstrating the critical importance of semantic-aware monitoring for autonomous agents.

% \subsubsection{Case Study 3: Multi-Agent Coordination Monitoring}

% AgentSight monitored three agents collaborating on software development (Agent A: architecture design, Agent B: implementation, Agent C: testing), capturing 12,847 total events with 342 correlated actions across 27 synchronization points involving 15 shared files and 3 network endpoints. The analysis revealed critical inefficiencies invisible to traditional monitoring: Agent B spent 34\% of time blocked on Agent A's multiple design revisions triggering cascading rework; file locking patterns showed resource contention with Agent C's testing conflicting with Agent B's implementation causing 23 retry cycles; inter-agent communication through shared files generated 1,800 unnecessary file system operations from 2-second polling intervals; yet agents developed emergent coordination with Agent B learning to batch changes, reducing test executions by 40\%. These insights demonstrate that explicit coordination mechanisms could reduce runtime by 25\% and message-based communication would eliminate 90\% of polling overhead, revealing how boundary tracing uniquely captures multi-agent system dynamics that application-level monitoring cannot observe across process boundaries.

% \section{Future Work}

% While AgentSight demonstrates boundary tracing's effectiveness, significant opportunities remain. We plan to enhance the correlation engine with machine learning to automatically detect novel anomalous behaviors beyond known patterns, extend from passive observation to active intervention through formal policy specifications that enable runtime enforcement as a "circuit breaker" for harmful actions, and address scale through distributed tracing across multi-node agents while integrating with OpenTelemetry for existing observability platforms. Privacy-preserving techniques will enable secure analysis without exposing sensitive prompt data, advancing toward comprehensive safety guarantees for autonomous AI systems.

\section{Conclusion}

This paper introduced AgentSight to bridge the critical semantic gap between an AI agent's intent and its system-level actions using novel \textit{boundary tracing} approach. By leveraging eBPF, the system monitors network and kernel events without instrumentation, causally linking LLM communications to their system-wide effects via a hybrid correlation engine. Our evaluation shows AgentSight effectively detects prompt injection attacks, reasoning loops, and multi-agent bottlenecks with under 3\% performance overhead. This "AI to watch AI" provides a foundational methodology for the secure and reliable deployment of increasingly autonomous AI systems.

% \textbf{Repository}: \url{https://github.com/eunomia-bpf/agentsight}

\bibliographystyle{ACM-Reference-Format}
\bibliography{ai}

\end{document}
