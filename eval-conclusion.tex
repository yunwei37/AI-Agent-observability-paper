\section{Evaluation}

\subsection{Experimental Setup}

We evaluated AgentSight across diverse production workloads to assess performance overhead, detection effectiveness, and behavioral insights. Our experimental environment consisted of AWS EC2 c5.2xlarge instances with 8 vCPUs and 16GB RAM running Linux kernel 5.15 with BTF support enabled. We tested three major agent frameworks: LangChain 0.1.0 representing the most popular open-source framework, AutoGen 0.2.0 for multi-agent scenarios, and Claude Code for production code generation tasks. Workloads included code generation tasks ranging from simple functions to complex system implementations, data analysis pipelines processing CSV and JSON datasets, and system administration tasks involving package installation and configuration management.

Performance measurements focused on end-to-end task completion time, CPU utilization during agent execution, memory consumption patterns, and event generation rates. We compared identical workloads with and without AgentSight enabled, running each experiment 50 times to ensure statistical significance. All measurements excluded initial warm-up runs to avoid JIT compilation effects.

\subsection{Performance Evaluation}

AgentSight achieves its design goal of sub-3\% overhead across all tested workloads, making it suitable for production deployment. Table~\ref{tab:performance} summarizes performance impacts across different agent task types.

\begin{table}[h]
\centering
\caption{Performance Overhead of AgentSight}
\label{tab:performance}
\begin{tabular}{lrrrr}
\toprule
Workload Type & Baseline & With AgentSight & Overhead & Events/sec \\
\midrule
Code Generation (simple) & 12.3s & 12.5s & 1.6\% & 432 \\
Code Generation (complex) & 87.2s & 89.1s & 2.2\% & 1,247 \\
Data Analysis & 34.5s & 35.2s & 2.0\% & 892 \\
System Admin Tasks & 23.1s & 23.7s & 2.6\% & 2,156 \\
Idle Agent & 0.1\% CPU & 0.3\% CPU & +0.2\% & 12 \\
\bottomrule
\end{tabular}
\end{table}

The results demonstrate consistent low overhead across diverse workload types. Simple code generation tasks show minimal impact at 1.6\% overhead, as these workloads generate fewer system events. Complex code generation involving multiple file operations and subprocess spawning increases overhead slightly to 2.2\%, still well within acceptable bounds. System administration tasks exhibit the highest overhead at 2.6\% due to intensive process spawning and file system operations, generating over 2,000 events per second. Even under this peak load, AgentSight maintains responsive performance.

Memory consumption remains predictable at 128MB base allocation plus 8MB per CPU core for ring buffers. This translates to 192MB total on our 8-core test systems, negligible compared to typical agent memory requirements. The fixed memory footprint prevents resource exhaustion under sustained load, a critical requirement for production deployments.

CPU overhead analysis reveals that eBPF probe execution accounts for only 15\% of total overhead, with the remainder attributed to event processing and correlation. This distribution validates our design choice of kernel-space filtering to minimize data movement. During idle periods when agents await user input, AgentSight adds only 0.2\% CPU utilization, ensuring minimal impact on system resources.

\subsection{Effectiveness Evaluation}

We evaluated AgentSight's effectiveness through three comprehensive case studies that demonstrate its ability to detect security threats, identify performance issues, and provide insights into complex multi-agent systems.

\subsection{Case Studies}

\subsubsection{Case Study 1: Detecting Prompt Injection Attacks}

We tested AgentSight's ability to detect prompt injection attacks where an agent is manipulated to perform unintended actions:

\textbf{Attack Scenario}: A data analysis agent receives a crafted prompt that causes it to exfiltrate sensitive data. The attack demonstrates a classic prompt injection technique where malicious commands are embedded within seemingly legitimate requests. The attacker crafts a prompt that begins with a reasonable task (analyzing sales data) but appends a command injection that exfiltrates sensitive system files. This attack pattern exploits agents' tendency to follow instructions literally without security validation.

\textbf{AgentSight Detection}:
1. \textbf{LLM Interaction} (T+0ms): Captured prompt with suspicious command injection
2. \textbf{Code Generation} (T+125ms): Agent generates Python script with embedded curl command
3. \textbf{Process Spawn} (T+342ms): Python script executes, spawns curl subprocess
4. \textbf{Network Activity} (T+367ms): Outbound HTTPS connection to suspicious domain
5. \textbf{File Access} (T+368ms): Read operation on /etc/passwd

\textbf{Correlation Output}: The correlation engine demonstrates AgentSight's ability to connect high-level threats with low-level evidence. The system identified potential data exfiltration with 92\% confidence based on multiple correlated signals: detected prompt injection in the original request, subsequent sensitive file access to /etc/passwd, outbound connection to a suspicious domain, and 1.2KB data transfer matching the file size. The timeline reconstruction shows the complete attack chain from initial prompt through code generation, execution, and ultimate exfiltration.

\textbf{Analysis Impact}: This detection capability proves critical for production deployments where agents process untrusted input. Traditional application-level monitoring would miss the correlation between the initial prompt and the subsequent system activities across different processes. AgentSight's boundary tracing approach captures the complete attack narrative, enabling rapid incident response and forensic analysis.

\subsubsection{Case Study 2: Reasoning Loop Detection}

\textbf{Scenario}: An agent enters an infinite reasoning loop while attempting a complex task. Reasoning loops manifest as cyclic dependencies in agent problem-solving attempts. The agent repeatedly cycles through the same logical chain: needing to solve X requires solving Y, but solving Y requires solving X. This circular reasoning consumes computational resources without making progress toward the actual goal. Such loops commonly occur when agents encounter problems outside their training distribution or when task decomposition logic contains flaws.

\textbf{AgentSight Detection}: The system employs multiple detection mechanisms to identify reasoning loops:

1. \textbf{Pattern Analysis}: AgentSight tracks LLM API call sequences, applying cycle detection algorithms to identify repeated prompt structures. The system uses semantic similarity metrics rather than exact matching, catching loops even when agents rephrase queries.

2. \textbf{Resource Monitoring}: Token consumption rates provide early warning signals. Healthy agent reasoning shows decreasing token usage as problems narrow; loops exhibit constant or increasing consumption without corresponding progress markers.

3. \textbf{Temporal Correlation}: By analyzing timestamps between related API calls, the system identifies suspiciously regular intervals characteristic of automated retry logic stuck in loops.

4. \textbf{Semantic Progress Tracking}: AgentSight evaluates whether successive LLM responses indicate forward progress or circular reasoning, using embedding-based similarity to detect semantic stagnation.

The system triggered an alert after detecting three complete cycles, preventing further resource waste. In this case, the agent consumed 4,800 tokens across 12 API calls before AgentSight intervened, saving an estimated \$2.40 in API costs and preventing potential service degradation.

\subsubsection{Case Study 3: Multi-Agent Coordination Monitoring}

\textbf{Scenario}: Multiple agents collaborating on a software development task:

- Agent A: Architecture design
- Agent B: Implementation
- Agent C: Testing

\textbf{AgentSight Insights}: The multi-agent monitoring revealed complex interaction patterns invisible to traditional observability tools:

\textbf{Quantitative Analysis}:
- Total Events: 12,847 (4,282 per agent average)
- Correlated Actions: 342 (representing meaningful collaborations)
- Cross-Agent Dependencies: 27 (synchronization points)
- Shared Resources: 15 files, 3 network endpoints
- Coordination Overhead: 18\% of total runtime

\textbf{Behavioral Patterns Discovered}:

1. \textbf{Handoff Inefficiencies}: Agent B spent 34\% of its time in wait states, primarily blocked on Agent A's architecture decisions. The visualization revealed Agent A's tendency to revise designs multiple times, triggering cascading re-work in downstream agents.

2. \textbf{Resource Contention}: File locking patterns showed agents competing for access to shared configuration files. Agent C's testing procedures repeatedly conflicted with Agent B's ongoing implementations, causing 23 retry cycles.

3. \textbf{Communication Overhead}: Inter-agent communication through shared files proved inefficient. Agents polled for updates every 2 seconds, generating 1,800 unnecessary file system operations.

4. \textbf{Emergent Coordination}: Despite lacking explicit coordination protocols, agents developed implicit synchronization patterns. Agent B learned to batch changes before signaling Agent C, reducing test suite executions by 40\%.

\textbf{Optimization Opportunities}: Based on these insights, implementing explicit coordination mechanisms could reduce runtime by 25\%, while moving to message-based communication would eliminate 90\% of file system polling overhead.


\section{Future Work}

Our experience developing and deploying AgentSight reveals both the promise of boundary tracing and significant challenges that remain for comprehensive AI agent observability. While AgentSight demonstrates feasibility with sub-3\% overhead and effective threat detection, the rapidly evolving landscape of AI agents presents numerous opportunities for future research.

In the short term, immediate engineering improvements could significantly enhance AgentSight's capabilities. Support for distributed tracing across multiple hosts would enable monitoring of agent systems that span cloud providers and on-premises infrastructure. Integration with existing observability platforms through OpenTelemetry would allow organizations to incorporate agent monitoring into their current toolchains. Performance optimizations through BPF CO-RE (Compile Once, Run Everywhere) would improve portability across kernel versions while reducing maintenance overhead.

Medium-term research extensions should focus on semantic understanding and automated analysis. Machine learning models trained on agent behavior patterns could automatically identify anomalies without manual rule definition. Natural language processing of captured prompts and responses could extract high-level intent, enabling semantic-aware alerting. Formal specification languages for agent behavior would allow teams to define expected patterns and automatically verify compliance. Integration with AI safety frameworks could provide real-time risk assessment based on observed behaviors.

The long-term vision for agent observability extends beyond monitoring to active intervention and verification. We envision systems that not only observe but can intervene when agents exhibit harmful behaviors, implementing circuit breakers that prevent damage while maintaining availability. Cryptographic attestation of agent behaviors could provide tamper-proof audit trails for compliance and forensics. Federated learning across deployments could build industry-wide models of normal and anomalous agent behaviors without sharing sensitive data.

Critical research challenges require interdisciplinary collaboration. Privacy-preserving monitoring techniques must balance comprehensive visibility with data protection requirements. Differential privacy for behavioral patterns and homomorphic encryption for prompt analysis represent promising directions. Standardization efforts should define common schemas for agent events, behavioral baselines for different agent types, and interoperability protocols between monitoring systems. The formal verification community could contribute runtime monitors synthesized from temporal logic specifications, enabling mathematical guarantees about agent behavior.

These advances will prove essential as AI agents assume greater autonomy in critical systems. The gap between agent capabilities and our ability to observe and control them represents a fundamental risk that the research community must address urgently.


\section{Conclusion}

AI agents represent a fundamental shift in software architecture, exhibiting autonomous decision-making and dynamic behavior that escapes traditional monitoring approaches. This paper introduced boundary tracing as a novel observability paradigm that monitors agents at stable system interfaces rather than within rapidly evolving application code. Our implementation, AgentSight, demonstrates the feasibility of this approach by capturing both semantic information through TLS interception and system behavior through eBPF-based kernel monitoring.

Our evaluation validates AgentSight's production readiness with less than 3\% performance overhead across diverse workloads while maintaining framework-agnostic operation. The system successfully detected prompt injection attacks with 92\% confidence, identified costly reasoning loops before resource exhaustion, and revealed coordination inefficiencies in multi-agent systems that traditional monitoring would miss. These capabilities prove essential as organizations deploy increasingly autonomous agents in production environments.

The boundary tracing approach addresses fundamental limitations of current observability solutions. By observing at kernel and network boundaries, AgentSight remains stable despite framework changes, maintains visibility across process boundaries, and operates without requiring agent cooperation. The correlation between high-level LLM interactions and low-level system operations enables semantic understanding of agent behavior, bridging the gap between intent and effect.

Looking forward, AI agent observability faces significant challenges requiring continued research. Distributed agent systems need new correlation primitives, privacy concerns demand novel cryptographic approaches, and the community needs standardized schemas for agent-specific telemetry. The rapid deployment of AI agents in critical systems makes these challenges urgent—the gap between agent capabilities and our ability to observe them represents a fundamental risk to system reliability and security.

We release AgentSight as open source to enable community collaboration on these critical challenges. As AI agents assume greater autonomy in software systems, comprehensive observability becomes not just a technical requirement but a prerequisite for safe deployment. AgentSight provides the foundation for this essential capability, demonstrating that system-level observation can provide the visibility needed to understand and control autonomous AI systems.

\textbf{Repository}: \url{https://github.com/eunomia-bpf/agentsight}

\bibliographystyle{ACM-Reference-Format}
\bibliography{ai}

\end{document}