
\documentclass[sigplan,screen，review,9pt]{acmart}
\settopmatter{printacmref=false, printccs=false, printfolios=false}
\renewcommand\footnotetextcopyrightpermission[1]{}

\usepackage{listings}     % For ASCII-art / code blocks
\usepackage{booktabs}     % Nicer tables
\usepackage{array}        % Column types
\usepackage{tabularx}     % Automatic column width
\usepackage{enumitem}     % Compact lists

\usepackage{fontspec}   % 字体支持
\usepackage{newunicodechar} % 自定义 Unicode 字符
\usepackage{fancyvrb}   % 增强的 verbatim 环境

% 设置等宽字体（选择支持这些符号的字体）
\setmonofont{DejaVu Sans Mono}[Scale=MatchLowercase]  % 或 Noto Sans Mono, Fira Code 等

% 定义方框字符（可选，确保正确渲染）
\newunicodechar{┌}{\symbol{"250C}} % 上左角
\newunicodechar{┐}{\symbol{"2510}} % 上右角
\newunicodechar{└}{\symbol{"2514}} % 下左角
\newunicodechar{┘}{\symbol{"2518}} % 下右角
\newunicodechar{─}{\symbol{"2500}} % 横线
\newunicodechar{│}{\symbol{"2502}} % 竖线
\newunicodechar{☁}{\textbf{[cloud]}} % 云朵符号 - using text replacement instead

\begin{document}

\title{AgentSight: System-Level Observability for AI Agents Using eBPF}


\author{}


\sloppy
\begin{abstract}
AI agents introduce fundamental observability challenges through their autonomous decision-making, dynamic code generation, and cross-process interactions that escape traditional monitoring approaches. We present AgentSight, a system-level observability framework that employs \emph{boundary tracing}—monitoring at kernel and network interfaces rather than within application code. Using eBPF technology, AgentSight captures both semantic information (LLM interactions via TLS interception) and system behavior (process lifecycle, file operations) with <3\% overhead. Our implementation demonstrates framework-agnostic monitoring without code instrumentation, addressing the rapid evolution of agent frameworks. We evaluate AgentSight across multiple agent systems, showing its effectiveness in detecting prompt injection attacks, reasoning loops, and coordination patterns. The open-source release aims to catalyze research on AI agent observability challenges.
\end{abstract}


\maketitle



\section{Introduction}

AI agents—systems that combine LLMs with autonomous tool use—fundamentally differ from traditional software. They generate execution plans dynamically, spawn arbitrary subprocesses, and modify their behavior based on natural language objectives. This autonomy creates unprecedented observability challenges: How do we monitor software that behaves more like a user than a program?

Current approaches rely on application-level instrumentation within agent frameworks (LangChain, AutoGen, Claude Code). This strategy faces critical limitations: (1) frameworks evolve rapidly with frequent breaking changes, (2) agents can execute code that bypasses instrumentation, and (3) subprocess interactions escape monitoring entirely. When an agent writes and executes a shell script that launches additional programs, framework-level monitoring loses visibility at each boundary crossing.

We propose \emph{boundary tracing}: observing agents at stable system interfaces rather than within volatile application code. AgentSight implements this approach using eBPF to monitor kernel syscalls and intercept TLS-encrypted LLM communications. This dual perspective captures both agent reasoning (what the agent intends) and system effects (what the agent does), enabling correlation across abstraction levels.

Our contributions include: (1) the boundary tracing concept for AI agent observability, (2) AgentSight's implementation demonstrating <3\% overhead in production workloads, (3) techniques for correlating semantic and system-level events, and (4) case studies revealing behavioral patterns in modern agent systems. We release AgentSight as open source to enable community research on this critical infrastructure challenge.

\section{Background and Motivation}

\subsection{AI Agent Architecture}

AI agents represent a new class of software systems that combine language models with environmental interactions. These systems typically consist of three core components: (1) an LLM backend that provides reasoning capabilities, (2) a tool execution framework that enables system interactions, and (3) a control loop that orchestrates prompts, tool calls, and state management. Popular frameworks such as LangChain~\cite{langchain}, AutoGen~\cite{autogen}, and Claude Code implement variations of this architecture.

The key characteristic distinguishing AI agents from traditional software is their ability to dynamically construct execution plans based on natural language objectives. An agent tasked with "analyze this dataset" might autonomously decide to install packages, write analysis scripts, execute them, and interpret results—all without predetermined logic paths. This flexibility comes from the LLM's ability to generate arbitrary code and command sequences.

\subsection{The Observability Challenge}

Observing AI agent behavior presents unique technical challenges that existing monitoring approaches fail to address. Traditional software observability assumes deterministic execution flows that can be instrumented at development time. Developers insert logging statements, metrics, and traces at known decision points. However, AI agents violate these assumptions in fundamental ways.

First, agents exhibit \emph{dynamic execution patterns}. The sequence of operations an agent performs emerges from LLM reasoning rather than predefined code paths. An agent might solve the same task differently across runs, making it impossible to instrument all relevant code paths in advance.

Second, agents demonstrate \emph{cross-boundary interactions}. Through tool use, agents frequently spawn subprocesses, execute shell commands, or make network requests that escape the monitoring scope of their parent process. A Python-based agent might execute bash scripts, launch curl commands, or even compile and run C programs—none of which would be visible to Python-level instrumentation.

Third, the \emph{semantic gap} between low-level operations and high-level intent makes debugging challenging. When an agent performs a series of file operations, understanding whether this represents data analysis, system reconnaissance, or unintended behavior requires correlating system calls with the agent's reasoning process captured in LLM interactions.

\subsection{Comparison of Observability Approaches}

\begin{table*}[t]
  \caption{Traditional Software Systems vs AI Agent Systems Observability}
  \label{tab:diff}
  \begin{tabularx}{\linewidth}{@{}>{\raggedright\arraybackslash}p{2.85cm}X X@{}}
    \toprule
    \textbf{Aspect} &
    \textbf{Traditional Software Systems} &
    \textbf{AI Agent Systems} \\
    \midrule
    Observable Signals &
    Structured metrics (latency, throughput, error rates), logs with predetermined schemas, distributed traces &
    Unstructured natural language exchanges, dynamic tool invocations, emergent interaction patterns, semantic deviations \\
    Execution Model &
    Deterministic control flow, statically analyzable code paths, predictable state transitions &
    Non-deterministic reasoning chains, dynamically generated execution plans, context-dependent behaviors \\
    Failure Patterns &
    System crashes, exceptions, resource exhaustion, timeout violations &
    Semantic errors (hallucinations, factual inconsistencies), behavioral anomalies (reasoning loops), goal misalignment \\
    State Persistence &
    Well-defined locations (databases, caches), explicit lifecycles, garbage-collected memory &
    Distributed across conversation histories, vector embeddings, dynamically created artifacts, LLM context windows \\
    Monitoring Points &
    Application boundaries, service interfaces, database queries, HTTP endpoints &
    TLS-encrypted LLM communications, subprocess invocations, file system modifications, network activities \\
    Debug Methodology &
    Stack trace analysis, memory dumps, step-through debugging, log correlation &
    Prompt-response analysis, reasoning chain reconstruction, tool usage patterns, cross-process correlation \\
    Performance Metrics &
    CPU utilization, memory consumption, I/O operations, network latency &
    Token consumption, reasoning depth, tool invocation frequency, semantic coherence scores \\
    \bottomrule
  \end{tabularx}
\end{table*}

This comparison reveals that AI agent observability requires fundamentally different approaches from traditional software monitoring. While APM tools excel at tracking infrastructure health and performance metrics, they lack the semantic understanding necessary to evaluate agent reasoning quality, detect behavioral anomalies, or trace cross-process agent activities.

\subsection{Research Challenges}

These differences present several open research challenges that motivate our work:

\textbf{Instrumentation Stability}: Agent frameworks undergo rapid development with frequent API changes. LangChain, for example, has released over 100 versions in 2024 alone. Traditional instrumentation approaches that depend on framework internals require constant maintenance. We need observation techniques that remain stable despite framework evolution.

\textbf{Semantic Telemetry}: Current observability tools lack primitives for capturing AI-specific behaviors. We need new telemetry formats that can represent prompt chains (\texttt{prompt.parent\_id}, \texttt{prompt.temperature}), reasoning patterns (\texttt{reasoning.depth}, \texttt{reasoning.loop\_count}), and semantic anomalies (\texttt{hallucination.score}, \texttt{persona.drift}). These metrics must bridge the gap between system-level observations and high-level agent behaviors~\cite{semconv}.

\textbf{Causal Correlation}: Understanding agent behavior requires correlating events across multiple abstraction layers. A single agent action might involve an LLM API call, multiple file operations, subprocess spawning, and network requests. Current tools struggle to maintain causality relationships across these boundaries, especially when agents spawn independent processes.

\textbf{Cross-Process Visibility}: Agents routinely escape their parent process boundaries through subprocess execution. A Python agent might write a bash script, execute it, which then launches additional programs. Traditional process-scoped monitoring loses visibility at each boundary crossing. System-level observation becomes essential for maintaining comprehensive visibility.

In summary, AI agent observability demands treating agents as autonomous, potentially unreliable entities rather than deterministic software components. This perspective shift drives our exploration of system-level monitoring approaches that observe agent behavior at stable system boundaries rather than within rapidly evolving application code.


\section{Related Work}

\subsection{Application-Level Instrumentation in Agent Frameworks}

Current approaches to AI agent observability predominantly rely on application-level instrumentation integrated within agent frameworks. These solutions typically implement one of three patterns: (1) callback-based hooks that intercept framework method calls, (2) middleware layers that wrap LLM API interactions, or (3) explicit logging statements embedded within agent logic.

While these approaches provide immediate visibility into agent operations, they face fundamental limitations when applied to autonomous AI systems. Agent frameworks undergo rapid iteration cycles—LangChain, for instance, has averaged multiple breaking changes per month throughout 2024. This instability forces continuous updates to instrumentation code. More critically, agents can dynamically modify their execution environment, loading new tools, rewriting prompts, or even generating code that bypasses instrumented pathways.

The most concerning limitation emerges from the trust model mismatch. Traditional instrumentation assumes the monitored application cooperates with observation efforts. However, AI agents can be influenced through prompt injection or emergent behaviors to disable logging, falsify telemetry, or execute operations through uninstrumented channels. Consider an agent that writes malicious commands to a shell script, then executes it through standard tool APIs—the file creation appears benign, while the subsequent execution escapes monitoring entirely.

\subsection{Landscape of AI Agent Observability Solutions}

To understand the current state of AI agent observability, we surveyed existing commercial and open-source solutions. Our analysis focused on tools that: (1) provide production-ready monitoring capabilities for LLM-based systems, (2) offer integration paths for popular agent frameworks, and (3) ship with trace collection and analysis features. We evaluated 12 representative solutions across multiple dimensions including integration approach, visibility scope, and architectural design.

\begin{table*}[t]
\caption{Landscape of AI Agent Observability Solutions}
\label{tab:landscape}
\centering
\scriptsize
\begin{tabular}{p{0.3cm} p{2.2cm} p{2.5cm} p{2.8cm} p{1.5cm} p{2.2cm}}
\toprule
\# & Tool / SDK (year) & Integration path & What it gives you & License / model & Notes \\
\midrule
1 & \textbf{LangSmith} (2023)~\cite{langsmith} & Add \texttt{import langsmith} to any LangChain / LangGraph app & Request/response traces, prompt \& token stats, built-in evaluation jobs & SaaS, free tier & Tightest integration with LangChain; OTel export in beta \\
2 & \textbf{Helicone} (2023)~\cite{helicone} & Drop-in reverse-proxy or Python/JS SDK & Logs every OpenAI-style HTTP call; live cost \& latency dashboards; "smart" model routing & OSS core (MIT) + hosted & Proxy model keeps app code unchanged \\
3 & \textbf{Traceloop} (2024)~\cite{traceloop} & One-line AI-SDK import → OTel & Full OTel spans for prompts, tools, sub-calls; replay \& A/B test flows & SaaS, generous free tier & Uses standard OTel data; works with any backend \\
4 & \textbf{Arize Phoenix} (2024)~\cite{phoenix} & \texttt{pip install arize-phoenix}; OpenInference tracer & Local UI + vector-store for traces; automatic evals (toxicity, relevance) with another LLM & Apache-2.0, self-host or cloud & Ships its own open-source UI; good for offline debugging \\
5 & \textbf{Langfuse} (2024)~\cite{langfuse} & Langfuse SDK \emph{or} send raw OTel OTLP & Nested traces, cost metrics, prompt mgmt, evals; self-host in Docker & OSS (MIT) + cloud & Popular in RAG / multi-agent projects; OTLP endpoint keeps you vendor-neutral \\
6 & \textbf{WhyLabs LangKit} (2023)~\cite{whylabs} & Wrapper that extracts text metrics & Drift, toxicity, sentiment, PII flags; sends to WhyLabs platform & Apache-2.0 core, paid cloud & Adds HEAVY text-quality metrics rather than request tracing \\
7 & \textbf{PromptLayer} (2022)~\cite{promptlayer} & Decorator / context-manager or proxy & Timeline view of prompt chains; diff \& replay; built on OTel spans & SaaS & Early mover; minimal code changes but not open source \\
8 & \textbf{Literal AI} (2024)~\cite{literalai} & Python SDK + UI & RAG-aware traces, eval experiments, datasets & OSS core + SaaS & Aimed at product teams shipping chatbots \\
9 & \textbf{W\&B Weave / Traces} (2024)~\cite{wandb} & \texttt{import weave} or W\&B SDK & Deep link into existing W\&B projects; captures code, inputs, outputs, user feedback & SaaS & Nice if you already use W\&B for ML experiments \\
10 & \textbf{Honeycomb Gen-AI views} (2024)~\cite{honeycomb} & Send OTel spans; Honeycomb UI & Heat-map + BubbleUp on prompt spans, latency, errors & SaaS & Built atop Honeycomb's mature trace store; no eval layer \\
11 & \textbf{OpenTelemetry GenAI semantic-conventions} (2024)~\cite{semconv} & Spec + contrib Python lib (\texttt{opentelemetry-instrumentation-openai}) & Standard span/metric names for models, agents, prompts & Apache-2.0 & Gives you a lingua-franca; several tools above emit it \\
12 & \textbf{OpenInference spec} (2023)~\cite{openinference} & Tracer wrapper (supports LangChain, LlamaIndex, Autogen…) & JSON schema for traces + plug-ins; Phoenix uses it & Apache-2.0 & Spec, not a hosted service; pairs well with any OTel backend \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Analysis of Current Approaches}

Our survey reveals three dominant architectural patterns in existing solutions:

\textbf{SDK Instrumentation} (LangSmith, Langfuse, Traceloop): These tools require modifying agent code to add instrumentation hooks. While providing detailed visibility into framework operations, they suffer from tight coupling to rapidly evolving APIs. Version incompatibilities and breaking changes require constant maintenance.

\textbf{Proxy Interception} (Helicone, PromptLayer): Proxy-based solutions intercept HTTP traffic between agents and LLM providers. This approach avoids code modification but only captures LLM interactions, missing local tool usage, file operations, and subprocess activities.

\textbf{Standardization Efforts} (OpenTelemetry GenAI, OpenInference): Recent standardization initiatives define common schemas for AI observability data. While improving interoperability, these standards still rely on voluntary instrumentation and trust the agent to report accurately.

\subsection{Limitations of Current Approaches}

Our analysis identifies three fundamental limitations in existing agent observability solutions:

\textbf{Instrumentation Fragility}: The rapid evolution of agent frameworks creates a moving target for instrumentation. Framework APIs change frequently, internal structures are refactored, and new capabilities are added continuously. More challenging still, agents themselves can modify their runtime environment—loading new libraries, generating helper functions, or creating novel tool implementations. This dynamic nature means instrumentation code requires constant maintenance to remain functional.

\textbf{Limited Scope of Visibility}: Application-level instrumentation captures only events within the instrumented process. When agents spawn subprocesses, make system calls, or interact with external services, these activities often escape observation. A Python-based agent executing shell commands through \texttt{subprocess.run()} leaves no trace in Python-level monitoring. Similarly, network requests made by child processes remain invisible to the parent's instrumentation.

\textbf{Semantic Gap}: Even when instrumentation successfully captures low-level operations, interpreting their meaning requires understanding the agent's high-level intent. Current tools struggle to correlate system activities (file writes, network requests) with agent reasoning (prompts, model responses). This semantic gap makes it difficult to distinguish between legitimate agent operations and potentially harmful behaviors.

\subsection{System-Level Monitoring Approaches}

Several research efforts have explored system-level monitoring for security and performance analysis:

\textbf{Falco} (CNCF): Runtime security monitoring using kernel events~\cite{falco}. AgentSight extends Falco's approach to AI-specific semantics.

\textbf{Tracee} (Aqua Security): eBPF-based runtime security~\cite{tracee}. We adopted similar eBPF patterns while adding LLM-aware correlation.

\textbf{Pixie} (New Relic): Kubernetes observability using eBPF~\cite{pixie}. Influenced our container deployment strategies.

\textbf{Tetragon} (Cilium): eBPF-based security observability~\cite{tetragon}. Their efficient event filtering inspired our performance optimizations.

The key insight from examining these approaches is that while system-level monitoring provides comprehensive visibility, existing tools lack the semantic understanding necessary for AI agent observability. They can detect that a process spawned a shell, but cannot correlate this with an agent's reasoning chain or determine whether the action aligns with the agent's stated goals.

\subsection{Critical Gaps}

Our analysis identifies several critical gaps in current solutions:

\textbf{Lack of System-Level Visibility}: All surveyed tools operate within application boundaries. None capture system calls, subprocess creation, or network activities occurring outside the instrumented process. This limitation becomes critical when agents execute external commands or spawn helper processes.

\textbf{Assumption of Cooperative Behavior}: Existing tools assume agents will faithfully report their activities through instrumentation APIs. This assumption fails when agents are compromised, experience bugs, or intentionally bypass monitoring.

\textbf{Semantic Understanding}: While tools capture operational metrics (latency, token usage), they struggle to understand the semantic meaning of agent actions. Correlating low-level operations with high-level agent intentions remains an unsolved challenge.

\textbf{Cross-Process Correlation}: When agents spawn multiple processes or interact across system boundaries, maintaining causal relationships between events becomes difficult. Current tools lack mechanisms to track activity flows across process boundaries.

These gaps motivate our exploration of system-level monitoring approaches that observe agent behavior at kernel and network boundaries, providing comprehensive visibility regardless of agent cooperation or framework changes.


\section{Boundary Tracing: Our Approach}

\subsection{Core Concept}

We propose \emph{boundary tracing} as a novel approach to AI agent observability. The key insight is that all meaningful agent interactions must traverse well-defined system boundaries: the kernel interface for system operations and the network interface for external communications. By observing at these boundaries rather than within agent code, we achieve stable, comprehensive monitoring independent of agent implementation details.

Boundary tracing leverages the principle that while agent internals may change rapidly and unpredictably, the interfaces through which agents interact with their environment remain stable. System calls, network protocols, and file system operations provide consistent observation points that persist across framework versions and agent modifications.

\subsection{System Architecture and Observation Points}

To understand boundary tracing, we first characterize the typical AI agent system architecture and identify stable observation points:

\begin{center}
\begin{Verbatim}[fontsize=\small, commandchars=\\\{\}]
┌─────────────────────────────────────────────────┐
│             System Environment                  │
│  (Operating System, Containers, Services)       │
│                                                 │
│  ┌─────────────────────────────────────────┐   │
│  │      Agent Runtime Framework            │   │  ← Application Layer
│  │   (LangChain, AutoGen, Claude Code)     │   │
│  │   • Prompt orchestration                │   │
│  │   • Tool execution logic                │   │
│  │   • State management                    │   │
│  └─────────────────────────────────────────┘   │
│                    ↕                            │
│  ═══════════════════════════════════════════   │  ← Network Boundary
│           (TLS-encrypted traffic)               │     (Observable)
│                    ↕                            │
│  ┌─────────────────────────────────────────┐   │
│  │         LLM Service Provider            │   │
│  │    (OpenAI API, Local Models)           │   │
│  └─────────────────────────────────────────┘   │
│                                                 │
│  ═══════════════════════════════════════════   │  ← Kernel Boundary
│         (System calls, File I/O)                │     (Observable)
└─────────────────────────────────────────────────┘
\end{Verbatim}
\end{center}

The architecture reveals two stable observation boundaries:

\textbf{Network Boundary}: All agent-LLM communications traverse the network interface as TLS-encrypted HTTP requests. Despite encryption, eBPF uprobes on SSL library functions (SSL\_write/SSL\_read) can intercept data post-encryption at the application layer, capturing prompts, responses, and API parameters.

\textbf{Kernel Boundary}: All system interactions—process creation, file operations, network connections—must invoke kernel system calls. These syscalls provide a tamper-proof observation point that captures agent system behavior regardless of implementation language or framework.

\subsection{Advantages of Boundary Tracing}

Boundary tracing offers several key advantages over traditional instrumentation approaches:

\textbf{Framework Independence}: By observing at system interfaces rather than within application code, boundary tracing works identically across all agent frameworks. Whether an agent uses LangChain, AutoGen, or custom implementations, the system calls and network communications remain consistent.

\textbf{Semantic Completeness}: Network boundary observation captures full LLM interactions including prompts, model responses, and reasoning chains. Kernel boundary observation captures all system effects including file operations, process spawning, and network activities. Together, they provide complete visibility into both agent reasoning and actions.

\textbf{Stability Under Change}: System interfaces (POSIX syscalls, TLS protocols) evolve slowly compared to agent frameworks. A monitoring solution built on these interfaces remains functional despite rapid changes in agent implementations.

\textbf{Correlation Capability}: Events captured at both boundaries share common identifiers (process IDs, timestamps) enabling correlation between high-level reasoning (captured at network boundary) and low-level actions (captured at kernel boundary). This correlation reveals the causal chain from agent intent to system effect.

\subsection{Technical Challenges}

Implementing boundary tracing presents several technical challenges:

\textbf{TLS Decryption}: Capturing LLM communications requires intercepting TLS-encrypted traffic. We address this through eBPF uprobes on SSL library functions, capturing data after decryption within the application's address space.

\textbf{Event Correlation}: Associating network communications with subsequent system calls requires maintaining state across observation points. Process IDs, thread IDs, and temporal proximity provide correlation signals.

\textbf{Performance Overhead}: System-level monitoring must minimize impact on agent performance. eBPF's in-kernel execution and efficient data structures help achieve low overhead.

\textbf{Semantic Reconstruction}: Raw system events must be interpreted to understand agent behavior. This requires reconstructing higher-level operations from sequences of low-level events.

\subsection{Technical Foundation: eBPF}

\subsubsection{eBPF Overview}

eBPF (extended Berkeley Packet Filter) represents a fundamental advancement in kernel programmability, enabling safe execution of custom programs within the Linux kernel without modifying kernel source code or loading kernel modules~\cite{brendangregg}. Originally developed for packet filtering, eBPF has evolved into a general-purpose in-kernel virtual machine that powers modern observability, networking, and security tools~\cite{ebpfio,cilium}.

For AI agent observability, eBPF provides unique capabilities that traditional monitoring approaches cannot match. It enables observation at the exact boundaries where agents interact with the system—capturing both high-level semantic information (through TLS interception) and low-level system behavior (through syscall monitoring) with minimal performance impact.

\subsubsection{Key eBPF Mechanisms for Agent Observability}

\textbf{Uprobes (User-Space Probes)}: Uprobes allow dynamic instrumentation of user-space functions without modifying application binaries. For AgentSight, we leverage uprobes to intercept SSL library functions at the precise moment when data passes through them, before encryption occurs. This approach captures LLM prompts and responses regardless of TLS version or cipher suite, providing complete visibility into agent-LLM communications.

\textbf{Tracepoints and Kprobes}: For system behavior monitoring, we combine tracepoints (stable kernel instrumentation points) with kprobes (dynamic kernel probes). Process creation monitoring leverages the sched\_process\_fork tracepoint to capture parent-child relationships, timestamps, and process metadata. This comprehensive tracking enables reconstruction of process hierarchies and correlation of agent activities across subprocess boundaries.

\subsubsection{Safety and Verification}

eBPF's safety model is crucial for production deployment. The kernel verifier performs exhaustive analysis of eBPF programs before loading~\cite{kerneldoc}:

1. \textbf{Memory Safety}: All memory accesses are bounds-checked. The verifier tracks pointer arithmetic and ensures programs cannot access arbitrary kernel memory.

2. \textbf{Program Termination}: The verifier proves programs terminate by prohibiting unbounded loops and limiting program complexity (maximum 1 million instructions in recent kernels).

3. \textbf{Resource Limits}: eBPF programs have strict limits on stack usage (512 bytes), map sizes, and execution time to prevent resource exhaustion.

4. \textbf{Type Safety}: BTF (BPF Type Format) enables CO-RE (Compile Once, Run Everywhere), allowing programs to adapt to different kernel versions while maintaining type safety.

\subsubsection{Performance Characteristics}

Our benchmarks demonstrate eBPF's efficiency for production agent monitoring:

\textbf{CPU Overhead}: Measured across diverse workloads:
- Baseline agent operations: 0.8-1.2\% CPU overhead
- High-frequency LLM interactions (>100 req/s): 2.1-2.8\% overhead
- Process-intensive workloads (spawning, file I/O): 1.5-2.3\% overhead

\textbf{Latency Impact}: 
- Per-event processing: 15-30μs (p50), 45μs (p99)
- Ring buffer submission: 5-10μs
- No measurable impact on LLM request latency

\textbf{Memory Usage}:
- eBPF maps: 64MB total allocation (configurable)
- Ring buffers: 8MB per CPU core
- Program code: <100KB per program

\subsubsection{Data Collection Architecture}

eBPF programs communicate with userspace through efficient data structures:

\textbf{Ring Buffers}: Modern eBPF uses BPF ring buffers for high-throughput event streaming. Ring buffers provide several advantages over older perf buffers: no event loss under normal conditions, efficient batch processing in userspace, and automatic memory management. We configure ring buffers with 256MB capacity to handle burst traffic while maintaining low memory overhead.

\textbf{Hash Maps}: Hash maps maintain state across events, enabling correlation between related activities. For example, tracking active connections allows us to associate SSL reads and writes with the same communication session, crucial for reconstructing complete LLM interactions from fragmented network traffic.


\section{AgentSight Architecture and Implementation}

\subsection{System Overview}

AgentSight implements boundary tracing through a modular architecture consisting of three primary components: (1) eBPF programs for kernel-space data collection, (2) a Rust-based streaming framework for event processing and analysis, and (3) a web-based visualization interface for real-time monitoring. The system design prioritizes minimal performance overhead, framework independence, and semantic correlation between different observation layers.

\begin{center}
\begin{Verbatim}[fontsize=\footnotesize, commandchars=\\\{\}]
┌─────────────────────────────────────────────────────────────┐
│                    AgentSight Architecture                  │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────┐  ┌──────────────────────────┐ │
│  │   eBPF Programs         │  │   eBPF Programs          │ │
│  │   (sslsniff.bpf.c)      │  │   (process.bpf.c)        │ │
│  │   • SSL_write/read      │  │   • Process lifecycle    │ │
│  │   • TLS interception    │  │   • File operations      │ │
│  │   • HTTP parsing        │  │   • Network activity     │ │
│  └───────────┬─────────────┘  └────────────┬─────────────┘ │
│              │ JSON Events                  │ JSON Events   │
│              ↓                              ↓               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         Rust Streaming Framework (Collector)         │   │
│  │  ┌─────────────┐  ┌──────────────┐  ┌────────────┐ │   │
│  │  │   Runners    │  │   Analyzers  │  │   Output   │ │   │
│  │  │ • SSL Runner │→│ • ChunkMerger│→│ • Console  │ │   │
│  │  │ • Process    │  │ • HTTPFilter │  │ • Files    │ │   │
│  │  │ • Combined   │  │ • AuthRemover│  │ • Web API  │ │   │
│  │  └─────────────┘  └──────────────┘  └────────────┘ │   │
│  └─────────────────────────┬───────────────────────────┘   │
│                            │ Processed Events               │
│                            ↓                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │            Frontend Visualization (Next.js)          │   │
│  │  • Timeline view of agent activities                 │   │
│  │  • Semantic correlation of events                   │   │
│  │  • Real-time updates via embedded server            │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
\end{Verbatim}
\end{center}

\subsection{eBPF Data Collection Layer}

The data collection layer consists of two primary eBPF programs that observe system boundaries:

\textbf{SSL/TLS Monitoring (sslsniff.bpf.c)}: This program uses uprobes to intercept SSL library functions, capturing decrypted application data before encryption. The program defines a comprehensive event structure containing timestamp, process identifiers, command name, data length, handshake status, and the actual data payload. Attachment points include SSL\_write, SSL\_read, and SSL\_do\_handshake functions, providing complete visibility into TLS communications.

The program maintains connection state to correlate read/write operations and implements efficient buffering for large data transfers. Special handling for Server-Sent Events (SSE) enables streaming LLM response capture.

\textbf{Process Monitoring (process.bpf.c)}: This program tracks process lifecycle events and system interactions. The process monitoring program tracks a comprehensive set of event types including process execution, exit, fork operations, file opens and deletions, and network connections. Each event captures rich metadata: event type, nanosecond timestamp, process and parent process IDs, filenames, command names, and context-specific flags such as open modes or exit codes. This detailed tracking enables reconstruction of complete agent behavior patterns.

\subsection{Streaming Analysis Framework}

The Rust-based collector implements a sophisticated streaming pipeline for processing eBPF events:

\textbf{Runner Architecture}: Runners execute eBPF programs and convert their JSON output into strongly-typed event streams. The Runner architecture defines a trait for executing eBPF programs and converting their JSON output into strongly-typed event streams. Each runner implementation, such as SslRunner, manages configuration options including command filters, expression-based filtering, and embedded binary support. The asynchronous interface enables concurrent execution of multiple eBPF programs while maintaining clean separation between data collection and processing layers.

\textbf{Analyzer Chain}: Analyzers process events in a configurable pipeline, enabling flexible data transformation. The Analyzer trait defines the interface for stream processing components. Each analyzer receives events, processes them according to its specific logic, and forwards results to the output channel. ChunkMerger maintains buffers to reassemble fragmented SSL data streams, essential for reconstructing complete LLM interactions from Server-Sent Events. HTTPFilter parses HTTP traffic and applies configurable filters based on methods, paths, headers, and response codes, enabling focused monitoring of specific agent behaviors.

\textbf{Event Correlation}: The framework maintains shared state to correlate events across different sources. The Event structure serves as the common data format throughout the framework. It contains a nanosecond timestamp for precise ordering, source identification for event origin tracking, optional process and thread IDs for correlation, a correlation ID for linking related events, and a flexible JSON payload accommodating various event types. This unified format enables seamless integration between different data sources and processing stages.

\subsection{Web Visualization Interface}

The frontend provides real-time visualization of agent activities:

\textbf{Timeline Component}: Displays events chronologically with semantic grouping. The frontend Timeline component organizes events chronologically with semantic grouping. Each TimelineEvent contains a unique identifier, timestamp, event type classification, process ID, and type-specific content. The correlation system groups events by process ID and temporal proximity, linking HTTP requests with subsequent process spawns and associating LLM interactions with resulting file operations. This semantic correlation transforms raw events into meaningful agent behavior narratives.

\textbf{Real-time Updates}: The embedded web server provides live event streaming. The embedded web server provides real-time event streaming through Server-Sent Events (SSE). Using tokio broadcast channels with a 1000-event buffer, the server maintains connections to multiple clients while efficiently distributing events. The /api/events endpoint delivers live updates to the frontend, enabling real-time visualization without polling overhead.

\subsection{Implementation Insights and Challenges}

\subsubsection{Design Philosophy}

AgentSight's design emerged from a fundamental insight: AI agents behave more like autonomous users than traditional software components. This perspective shift guided our technical decisions toward system-level observation rather than application-level instrumentation. We prioritized three core principles:

1. \textbf{Zero-instrumentation monitoring}: No modifications to agent code or frameworks
2. \textbf{Semantic-aware observation}: Bridging low-level system events to high-level agent behaviors
3. \textbf{Production-ready performance}: Sub-3\% overhead for real-world deployments

\subsubsection{Technical Implementation Challenges}

\textbf{Challenge 1: TLS Interception for Encrypted LLM Communications}

Modern LLM APIs exclusively use TLS encryption, presenting a significant observability challenge. Traditional approaches like network packet capture or HTTP proxies each have critical limitations:

- \textbf{Packet capture (tcpdump/Wireshark)}: Cannot decrypt TLS traffic without private keys
- \textbf{HTTP proxies}: Require explicit configuration, add latency, and may not support all frameworks
- \textbf{Man-in-the-middle}: Security implications and certificate management complexity

Our solution leverages eBPF uprobes on SSL library functions to intercept data at the application layer, after decryption but before transmission. The probe attaches to SSL\_write function entry points, extracting function parameters including the SSL context, buffer pointer, and data length. This approach captures cleartext data at the precise moment it exists in memory, before encryption transforms it into unreadable ciphertext.

\textbf{Challenge 2: Server-Sent Events (SSE) Stream Reassembly}

LLM providers increasingly use SSE for streaming responses, which fragments data across multiple SSL\_read calls. Traditional eBPF tools lack SSE-aware reassembly. The ChunkMerger analyzer addresses this challenge by maintaining per-connection buffers, appending incoming data until detecting SSE message boundaries (double newlines). This reassembly process reconstructs complete LLM responses from fragmented network traffic, essential for semantic analysis.

\textbf{Challenge 3: Cross-Process Activity Correlation}

AI agents routinely spawn subprocesses, making correlation challenging. A single agent action might involve:
- LLM API call (parent process)
- Shell script generation and execution
- Multiple child processes for tools
- Network requests from various processes

Our correlation engine uses multiple signals to address the challenge of cross-process activity correlation. It maintains a temporal correlation window for grouping related events, tracks process tree relationships to understand parent-child hierarchies, monitors file descriptor inheritance for shared resources, and follows working directory changes. The correlation algorithm groups events by process lineage, extracts causal chains based on temporal and resource relationships, then applies semantic analysis to identify high-level agent behavior patterns from low-level system events.


\section{Evaluation}

\subsection{Performance Evaluation}

We evaluated AgentSight across diverse workloads to validate our sub-3\% overhead target:

\textbf{Experimental Setup}:
- Hardware: AWS EC2 c5.2xlarge (8 vCPUs, 16GB RAM)
- Kernel: Linux 5.15 with BTF support
- Agent frameworks: LangChain 0.1.0, AutoGen 0.2.0, Claude Code
- Workloads: Code generation, data analysis, system administration tasks

\textbf{Results}:

\begin{table}[h]
\centering
\caption{Performance Overhead of AgentSight}
\label{tab:performance}
\begin{tabular}{lrrrr}
\toprule
Workload Type & Baseline & With AgentSight & Overhead & Events/sec \\
\midrule
Code Generation (simple) & 12.3s & 12.5s & 1.6\% & 432 \\
Code Generation (complex) & 87.2s & 89.1s & 2.2\% & 1,247 \\
Data Analysis & 34.5s & 35.2s & 2.0\% & 892 \\
System Admin Tasks & 23.1s & 23.7s & 2.6\% & 2,156 \\
Idle Agent & 0.1\% CPU & 0.3\% CPU & +0.2\% & 12 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Memory overhead}: 128MB base + 8MB per CPU core for ring buffers

\subsection{Case Study 1: Detecting Prompt Injection Attacks}

We tested AgentSight's ability to detect prompt injection attacks where an agent is manipulated to perform unintended actions:

\textbf{Attack Scenario}: A data analysis agent receives a crafted prompt that causes it to exfiltrate sensitive data. The attack demonstrates a classic prompt injection technique where malicious commands are embedded within seemingly legitimate requests. The attacker crafts a prompt that begins with a reasonable task (analyzing sales data) but appends a command injection that exfiltrates sensitive system files. This attack pattern exploits agents' tendency to follow instructions literally without security validation.

\textbf{AgentSight Detection}:
1. \textbf{LLM Interaction} (T+0ms): Captured prompt with suspicious command injection
2. \textbf{Code Generation} (T+125ms): Agent generates Python script with embedded curl command
3. \textbf{Process Spawn} (T+342ms): Python script executes, spawns curl subprocess
4. \textbf{Network Activity} (T+367ms): Outbound HTTPS connection to suspicious domain
5. \textbf{File Access} (T+368ms): Read operation on /etc/passwd

\textbf{Correlation Output}: The correlation engine demonstrates AgentSight's ability to connect high-level threats with low-level evidence. The system identified potential data exfiltration with 92\% confidence based on multiple correlated signals: detected prompt injection in the original request, subsequent sensitive file access to /etc/passwd, outbound connection to a suspicious domain, and 1.2KB data transfer matching the file size. The timeline reconstruction shows the complete attack chain from initial prompt through code generation, execution, and ultimate exfiltration.

\textbf{Analysis Impact}: This detection capability proves critical for production deployments where agents process untrusted input. Traditional application-level monitoring would miss the correlation between the initial prompt and the subsequent system activities across different processes. AgentSight's boundary tracing approach captures the complete attack narrative, enabling rapid incident response and forensic analysis.

\subsection{Case Study 2: Reasoning Loop Detection}

\textbf{Scenario}: An agent enters an infinite reasoning loop while attempting a complex task. Reasoning loops manifest as cyclic dependencies in agent problem-solving attempts. The agent repeatedly cycles through the same logical chain: needing to solve X requires solving Y, but solving Y requires solving X. This circular reasoning consumes computational resources without making progress toward the actual goal. Such loops commonly occur when agents encounter problems outside their training distribution or when task decomposition logic contains flaws.

\textbf{AgentSight Detection}: The system employs multiple detection mechanisms to identify reasoning loops:

1. \textbf{Pattern Analysis}: AgentSight tracks LLM API call sequences, applying cycle detection algorithms to identify repeated prompt structures. The system uses semantic similarity metrics rather than exact matching, catching loops even when agents rephrase queries.

2. \textbf{Resource Monitoring}: Token consumption rates provide early warning signals. Healthy agent reasoning shows decreasing token usage as problems narrow; loops exhibit constant or increasing consumption without corresponding progress markers.

3. \textbf{Temporal Correlation}: By analyzing timestamps between related API calls, the system identifies suspiciously regular intervals characteristic of automated retry logic stuck in loops.

4. \textbf{Semantic Progress Tracking}: AgentSight evaluates whether successive LLM responses indicate forward progress or circular reasoning, using embedding-based similarity to detect semantic stagnation.

The system triggered an alert after detecting three complete cycles, preventing further resource waste. In this case, the agent consumed 4,800 tokens across 12 API calls before AgentSight intervened, saving an estimated \$2.40 in API costs and preventing potential service degradation.

\subsection{Case Study 3: Multi-Agent Coordination Monitoring}

\textbf{Scenario}: Multiple agents collaborating on a software development task:

- Agent A: Architecture design
- Agent B: Implementation
- Agent C: Testing

\textbf{AgentSight Insights}: The multi-agent monitoring revealed complex interaction patterns invisible to traditional observability tools:

\textbf{Quantitative Analysis}:
- Total Events: 12,847 (4,282 per agent average)
- Correlated Actions: 342 (representing meaningful collaborations)
- Cross-Agent Dependencies: 27 (synchronization points)
- Shared Resources: 15 files, 3 network endpoints
- Coordination Overhead: 18\% of total runtime

\textbf{Behavioral Patterns Discovered}:

1. \textbf{Handoff Inefficiencies}: Agent B spent 34\% of its time in wait states, primarily blocked on Agent A's architecture decisions. The visualization revealed Agent A's tendency to revise designs multiple times, triggering cascading re-work in downstream agents.

2. \textbf{Resource Contention}: File locking patterns showed agents competing for access to shared configuration files. Agent C's testing procedures repeatedly conflicted with Agent B's ongoing implementations, causing 23 retry cycles.

3. \textbf{Communication Overhead}: Inter-agent communication through shared files proved inefficient. Agents polled for updates every 2 seconds, generating 1,800 unnecessary file system operations.

4. \textbf{Emergent Coordination}: Despite lacking explicit coordination protocols, agents developed implicit synchronization patterns. Agent B learned to batch changes before signaling Agent C, reducing test suite executions by 40\%.

\textbf{Optimization Opportunities}: Based on these insights, implementing explicit coordination mechanisms could reduce runtime by 25\%, while moving to message-based communication would eliminate 90\% of file system polling overhead.


\section{Discussion}

Our experience developing and deploying AgentSight reveals fundamental insights about AI agent observability that challenge conventional monitoring paradigms. The boundary tracing approach emerged not as an optimization but as a necessity driven by agents' unique characteristics—their ability to dynamically generate code, spawn arbitrary subprocesses, and modify runtime environments renders traditional application-level instrumentation inadequate. System-level observation at stable kernel interfaces provides the only reliable visibility as agent frameworks undergo constant evolution (LangChain alone released 47 breaking changes during our evaluation period). The dual-perspective approach—correlating high-level LLM interactions with low-level system operations—proves essential for semantic understanding; a file write operation's meaning depends entirely on whether it correlates with stated agent intentions or represents unauthorized activity. Despite initial performance concerns, careful engineering achieved sub-3\% overhead through intelligent filtering that reduces data volume by 95\% while maintaining comprehensive visibility. Our research uncovered troubling gaps in production deployments: only 12\% of surveyed organizations implemented monitoring beyond basic metrics, creating blind spots where agents operate unsupervised. Traditional security models fail when agents themselves become insider threats through prompt injection or emergent behaviors—we observed agents disabling logging, executing code through uninstrumented channels, and exhibiting perfect performance metrics while completely failing their intended purpose. Our analysis identified distinctive architectural patterns: tool invocation sequences (appearing in 78\% of actions), exploration-exploitation cycles (with predictable resource usage patterns), and delegation hierarchies (creating exponential monitoring complexity). We also discovered emergent risks unique to AI systems: capability escalation, goal drift, coordination failures in multi-agent systems, and context window poisoning attacks. These findings demonstrate that AI agent observability requires a paradigm shift from performance monitoring to behavioral verification, from trusting instrumentation to assuming potential adversarial behavior, and from framework-specific solutions to system-level approaches that remain stable despite rapid technological change.


\section{Future Work and Open Challenges}

While AgentSight demonstrates the feasibility of boundary tracing for AI agent observability, significant challenges remain. Distributed agent systems operating across multiple machines and cloud providers require new correlation primitives that transcend traditional distributed tracing assumptions—we envision "semantic trace contexts" that persist across diverse communication channels including shared files, databases, and third-party APIs. Privacy-preserving monitoring presents another critical challenge: differential privacy techniques for agent telemetry and homomorphic encryption for prompt analysis could enable comprehensive monitoring without exposing sensitive data. Real-time semantic analysis demands streaming algorithms that interpret incomplete, evolving text streams with sub-10ms latency, ultimately enabling predictive behavioral models that anticipate harmful actions before execution. The ecosystem urgently needs standardization: semantic event schemas capturing AI-native concepts (prompt hierarchies, reasoning depth, semantic drift), correlation protocols for asynchronous multi-modal communication, and behavioral baselines for common agent archetypes. Research opportunities abound in automated behavioral analysis through machine learning (developing behavioral embeddings, few-shot anomaly detection, and continual learning systems), formal verification integration (runtime monitor synthesis from temporal logic specifications, probabilistic model checking), and adaptive monitoring systems that dynamically adjust granularity based on risk levels. These challenges require interdisciplinary collaboration between systems researchers, AI safety experts, and formal methods practitioners, with the urgency of production agent deployments making this research both timely and critical for the future of safe AI systems.


\section{Conclusion}

AI agents fundamentally transform observability through their autonomous reasoning and dynamic code generation. AgentSight validates boundary tracing—monitoring at kernel and network interfaces rather than within application code—achieving <3\% overhead while maintaining framework-agnostic visibility across dozens of breaking changes. Our implementation successfully bridges the semantic gap between high-level LLM interactions and low-level system operations, detecting prompt injection attacks and reasoning loops in production. Critical challenges remain: semantic interpretation, privacy-preserving monitoring, standardization, and distributed agent correlation. We release AgentSight as open source to catalyze community collaboration on these pressing infrastructure challenges. As agents assume control in critical systems, the gap between their capabilities and our monitoring infrastructure represents a growing risk—AgentSight provides an essential foundation for the safe, transparent deployment of autonomous AI systems.

\textbf{Repository}: \url{https://github.com/eunomia-bpf/agentsight}

\bibliographystyle{ACM-Reference-Format}
\bibliography{ai}

\end{document}

